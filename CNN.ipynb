{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMO0lM9I5i99lXtwiSHYTmD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shsieh005/ProjectAI/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolution"
      ],
      "metadata": {
        "id": "f5qEL-k--CJk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3jIbK2PB8pg4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as f\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "learning_rate = 1e-4 # 0.0001"
      ],
      "metadata": {
        "id": "5YMwlZep9dJn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor() , download=True) # ToTensor() 每張照片0-255 -> 0-1 (標準化)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size = BATCH_SIZE, shuffle = False)\n",
        "iterator = iter(train_loader)\n",
        "images, labels = next(iterator)\n",
        "fig, axes = plt.subplots(1,20, figsize=(15, 15))\n",
        "for i in range(20):\n",
        "  axes[i].imshow(images[i][0], cmap = 'gray')\n",
        "  axes[i].set_axis_off()\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "id": "nopnYda59jv3",
        "outputId": "4ec92600-01d6-4aa3-887b-cc053f4110a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    \"\"\"\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1) # 16x28x28  \n",
        "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1) # 16x28x28\n",
        "    self.pool1 = nn.MaxPool2d(2,2) # 16x14x14\n",
        "    self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1) # 32x14x14\n",
        "    self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1) # 32x14x14\n",
        "    self.pool2 = nn.MaxPool2d(2,2) # 32x7x7  # height and width decrease, channels increase\n",
        "    self.fc1 = nn.Linear(32*7*7,128) \n",
        "    self.fc2 = nn.Linear(128,10)\n",
        "    \"\"\"\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),  # 16x28x28  # ouput channels = 16 -> 16 filters\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1), # 16x28x28\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2), # 16x14x14\n",
        "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1), # 32x14x14\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1), # 32x14x14\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "    )\n",
        "    # 拉直 -> 神經元\n",
        "    self.fcs = nn.Sequential( \n",
        "        nn.Linear(32*7*7, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 10)\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool1(x)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = self.pool2(x) # 64 x 32 x 7 x 7\n",
        "    x = x.view(-1,32*7*7) # 64 x 1568 (拉直)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    output = self.fc2(x)\n",
        "    \"\"\"\n",
        "    x = self.conv(x)\n",
        "    x = x.view(-1, 32*7*7)\n",
        "    output = self.fcs(x)\n",
        "    return output"
      ],
      "metadata": {
        "id": "jgk05ZF9-MBC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = ConvNet().to(device)\n",
        "print(cnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmsEBM5IA8dC",
        "outputId": "7d1ecfd1-1227-405e-bcde-34dfa8515926"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvNet(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU()\n",
            "    (7): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU()\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fcs): Sequential(\n",
            "    (0): Linear(in_features=1568, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "17r7w-0iA9BI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST:6萬張照片 batch size:64 60000/64=938(1 epoch)\n",
        "total_steps = len(train_loader)\n",
        "for epoch in range(epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # origin shape: [64, 1, 28, 28]\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = cnn(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad() # 梯度歸0 (對x做微分會一直累加, 但和上一個batch肯定不相關)\n",
        "    loss.backward() # 梯度算gradient descent \n",
        "    optimizer.step() # 往前走一步 \n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print (f'Epoch {epoch+1}, Step [{i+1}/{total_steps}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9SJhUhtGmwm",
        "outputId": "a0b4276a-d70a-4009-b1b7-ad58976675b9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Step [100/938], Loss: 1.8295\n",
            "Epoch 1, Step [200/938], Loss: 0.7582\n",
            "Epoch 1, Step [300/938], Loss: 0.5016\n",
            "Epoch 1, Step [400/938], Loss: 0.3201\n",
            "Epoch 1, Step [500/938], Loss: 0.3754\n",
            "Epoch 1, Step [600/938], Loss: 0.2803\n",
            "Epoch 1, Step [700/938], Loss: 0.2187\n",
            "Epoch 1, Step [800/938], Loss: 0.0910\n",
            "Epoch 1, Step [900/938], Loss: 0.2312\n",
            "Epoch 2, Step [100/938], Loss: 0.1936\n",
            "Epoch 2, Step [200/938], Loss: 0.2008\n",
            "Epoch 2, Step [300/938], Loss: 0.1625\n",
            "Epoch 2, Step [400/938], Loss: 0.2245\n",
            "Epoch 2, Step [500/938], Loss: 0.1120\n",
            "Epoch 2, Step [600/938], Loss: 0.1036\n",
            "Epoch 2, Step [700/938], Loss: 0.1674\n",
            "Epoch 2, Step [800/938], Loss: 0.0397\n",
            "Epoch 2, Step [900/938], Loss: 0.0863\n",
            "Epoch 3, Step [100/938], Loss: 0.1608\n",
            "Epoch 3, Step [200/938], Loss: 0.0560\n",
            "Epoch 3, Step [300/938], Loss: 0.1016\n",
            "Epoch 3, Step [400/938], Loss: 0.1048\n",
            "Epoch 3, Step [500/938], Loss: 0.1266\n",
            "Epoch 3, Step [600/938], Loss: 0.0232\n",
            "Epoch 3, Step [700/938], Loss: 0.0884\n",
            "Epoch 3, Step [800/938], Loss: 0.1360\n",
            "Epoch 3, Step [900/938], Loss: 0.1705\n",
            "Epoch 4, Step [100/938], Loss: 0.0368\n",
            "Epoch 4, Step [200/938], Loss: 0.1139\n",
            "Epoch 4, Step [300/938], Loss: 0.0477\n",
            "Epoch 4, Step [400/938], Loss: 0.0575\n",
            "Epoch 4, Step [500/938], Loss: 0.0834\n",
            "Epoch 4, Step [600/938], Loss: 0.0978\n",
            "Epoch 4, Step [700/938], Loss: 0.0224\n",
            "Epoch 4, Step [800/938], Loss: 0.0394\n",
            "Epoch 4, Step [900/938], Loss: 0.0853\n",
            "Epoch 5, Step [100/938], Loss: 0.0287\n",
            "Epoch 5, Step [200/938], Loss: 0.0922\n",
            "Epoch 5, Step [300/938], Loss: 0.0809\n",
            "Epoch 5, Step [400/938], Loss: 0.1240\n",
            "Epoch 5, Step [500/938], Loss: 0.0201\n",
            "Epoch 5, Step [600/938], Loss: 0.0169\n",
            "Epoch 5, Step [700/938], Loss: 0.0114\n",
            "Epoch 5, Step [800/938], Loss: 0.0210\n",
            "Epoch 5, Step [900/938], Loss: 0.0150\n",
            "Epoch 6, Step [100/938], Loss: 0.0590\n",
            "Epoch 6, Step [200/938], Loss: 0.0491\n",
            "Epoch 6, Step [300/938], Loss: 0.0203\n",
            "Epoch 6, Step [400/938], Loss: 0.0070\n",
            "Epoch 6, Step [500/938], Loss: 0.0065\n",
            "Epoch 6, Step [600/938], Loss: 0.0184\n",
            "Epoch 6, Step [700/938], Loss: 0.1036\n",
            "Epoch 6, Step [800/938], Loss: 0.0053\n",
            "Epoch 6, Step [900/938], Loss: 0.0124\n",
            "Epoch 7, Step [100/938], Loss: 0.0454\n",
            "Epoch 7, Step [200/938], Loss: 0.0257\n",
            "Epoch 7, Step [300/938], Loss: 0.1613\n",
            "Epoch 7, Step [400/938], Loss: 0.0252\n",
            "Epoch 7, Step [500/938], Loss: 0.0226\n",
            "Epoch 7, Step [600/938], Loss: 0.0429\n",
            "Epoch 7, Step [700/938], Loss: 0.0826\n",
            "Epoch 7, Step [800/938], Loss: 0.1018\n",
            "Epoch 7, Step [900/938], Loss: 0.0438\n",
            "Epoch 8, Step [100/938], Loss: 0.0434\n",
            "Epoch 8, Step [200/938], Loss: 0.0725\n",
            "Epoch 8, Step [300/938], Loss: 0.0687\n",
            "Epoch 8, Step [400/938], Loss: 0.0044\n",
            "Epoch 8, Step [500/938], Loss: 0.0105\n",
            "Epoch 8, Step [600/938], Loss: 0.0062\n",
            "Epoch 8, Step [700/938], Loss: 0.1368\n",
            "Epoch 8, Step [800/938], Loss: 0.0065\n",
            "Epoch 8, Step [900/938], Loss: 0.0282\n",
            "Epoch 9, Step [100/938], Loss: 0.0557\n",
            "Epoch 9, Step [200/938], Loss: 0.0316\n",
            "Epoch 9, Step [300/938], Loss: 0.0162\n",
            "Epoch 9, Step [400/938], Loss: 0.0132\n",
            "Epoch 9, Step [500/938], Loss: 0.0072\n",
            "Epoch 9, Step [600/938], Loss: 0.0020\n",
            "Epoch 9, Step [700/938], Loss: 0.0344\n",
            "Epoch 9, Step [800/938], Loss: 0.0133\n",
            "Epoch 9, Step [900/938], Loss: 0.0153\n",
            "Epoch 10, Step [100/938], Loss: 0.2726\n",
            "Epoch 10, Step [200/938], Loss: 0.0174\n",
            "Epoch 10, Step [300/938], Loss: 0.0063\n",
            "Epoch 10, Step [400/938], Loss: 0.0021\n",
            "Epoch 10, Step [500/938], Loss: 0.0065\n",
            "Epoch 10, Step [600/938], Loss: 0.0049\n",
            "Epoch 10, Step [700/938], Loss: 0.0462\n",
            "Epoch 10, Step [800/938], Loss: 0.0770\n",
            "Epoch 10, Step [900/938], Loss: 0.1331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = cnn(images)\n",
        "\n",
        "    # max returns (value ,index)\n",
        "    _, predicted = torch.max(outputs, 1) # 只要 index(預測分類), value(預測機率)不要\n",
        "    n_samples += labels.size(0)\n",
        "    n_correct += (predicted == labels).sum().item() # 64筆裡面以幾筆和label一樣\n",
        "\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'Accuracy of the network: {acc} %')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNcn8sWNHmdW",
        "outputId": "3751f67c-1d6f-4daf-f0e9-48632ace4734"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network: 98.87 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ],
      "metadata": {
        "id": "wK5KYxknLVFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for p in cnn.parameters():\n",
        "  print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmquzCENJUS5",
        "outputId": "0e199faa-0ca5-4047-eb8c-282ea289e9c4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.3463,  0.2325,  0.3740],\n",
            "          [-0.1886, -0.1340,  0.1709],\n",
            "          [-0.3146,  0.1113,  0.2362]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3759, -0.0614,  0.2793],\n",
            "          [ 0.0345,  0.1504,  0.0620],\n",
            "          [-0.3192,  0.0775,  0.2444]]],\n",
            "\n",
            "\n",
            "        [[[-0.0576,  0.1991, -0.0623],\n",
            "          [-0.0581,  0.2676,  0.3224],\n",
            "          [ 0.3732,  0.1530, -0.1578]]],\n",
            "\n",
            "\n",
            "        [[[-0.1692, -0.1209,  0.3697],\n",
            "          [-0.1715, -0.0878, -0.1820],\n",
            "          [-0.2093, -0.2761, -0.1611]]],\n",
            "\n",
            "\n",
            "        [[[-0.0674,  0.1032, -0.0365],\n",
            "          [ 0.3903,  0.1845,  0.3247],\n",
            "          [ 0.4086, -0.1361, -0.1586]]],\n",
            "\n",
            "\n",
            "        [[[-0.2143,  0.2648, -0.1210],\n",
            "          [ 0.1781,  0.3657,  0.3596],\n",
            "          [ 0.3371, -0.1752,  0.3453]]],\n",
            "\n",
            "\n",
            "        [[[-0.3730, -0.1593, -0.3387],\n",
            "          [ 0.1238, -0.2337, -0.0296],\n",
            "          [-0.2492, -0.1985, -0.2679]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0532,  0.0490,  0.0088],\n",
            "          [ 0.3192,  0.0842, -0.2367],\n",
            "          [ 0.3910,  0.4578,  0.3688]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2742,  0.2918, -0.0959],\n",
            "          [-0.3112, -0.1165,  0.3513],\n",
            "          [-0.1172, -0.1167,  0.3915]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3845,  0.0998, -0.2165],\n",
            "          [ 0.3502,  0.3432,  0.0561],\n",
            "          [-0.1467,  0.2356,  0.2576]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1157, -0.2279, -0.2737],\n",
            "          [ 0.1080,  0.0610, -0.3185],\n",
            "          [ 0.3863, -0.2859, -0.2060]]],\n",
            "\n",
            "\n",
            "        [[[-0.3206, -0.1865, -0.2693],\n",
            "          [-0.2640,  0.0623, -0.0800],\n",
            "          [-0.0239,  0.2409,  0.2410]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0194,  0.0924, -0.0923],\n",
            "          [ 0.1958, -0.1386,  0.0332],\n",
            "          [ 0.4002,  0.4939,  0.2017]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2109,  0.0250,  0.0073],\n",
            "          [-0.2231, -0.2276,  0.2302],\n",
            "          [ 0.3407,  0.2133,  0.2325]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3036, -0.0932, -0.1913],\n",
            "          [ 0.3374,  0.1942,  0.1698],\n",
            "          [ 0.4037, -0.1160,  0.2656]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3375,  0.4613,  0.2562],\n",
            "          [ 0.2876, -0.0947,  0.1386],\n",
            "          [-0.0503,  0.2755, -0.2582]]]], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0116, -0.1576,  0.3191,  0.1504,  0.0231,  0.3151,  0.0937, -0.1581,\n",
            "        -0.1741,  0.0534,  0.1663,  0.1375,  0.0300, -0.1550,  0.1799,  0.0107],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[[[-1.0612e-02, -6.3614e-02,  1.5166e-02],\n",
            "          [ 4.6912e-02, -5.7694e-02, -7.7431e-02],\n",
            "          [ 9.7192e-02,  4.3181e-02, -1.6678e-02]],\n",
            "\n",
            "         [[ 4.0432e-02,  4.4968e-02, -4.4412e-02],\n",
            "          [-3.5651e-02,  3.1849e-02,  6.1504e-02],\n",
            "          [ 9.2969e-02, -1.8606e-02, -5.0408e-02]],\n",
            "\n",
            "         [[ 9.1109e-02, -2.7930e-02,  8.3151e-02],\n",
            "          [-9.1254e-04,  2.8728e-04, -3.1108e-02],\n",
            "          [ 1.2784e-01,  7.3746e-02, -5.8905e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6348e-02,  4.6895e-02,  1.1333e-01],\n",
            "          [ 8.5814e-02,  5.1673e-03,  1.2778e-01],\n",
            "          [ 2.5132e-02,  5.6151e-02, -2.2380e-02]],\n",
            "\n",
            "         [[ 3.7665e-02, -2.4826e-02, -3.3807e-02],\n",
            "          [ 4.7744e-02,  4.9028e-02,  1.0152e-01],\n",
            "          [ 3.1798e-02,  6.1331e-02,  9.6161e-02]],\n",
            "\n",
            "         [[-4.9227e-02,  8.2038e-02,  5.0241e-02],\n",
            "          [-3.9432e-02,  2.2499e-02, -1.1362e-02],\n",
            "          [ 1.1498e-01,  6.3532e-02,  5.2070e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.4265e-02, -8.1686e-02,  1.2667e-02],\n",
            "          [-2.9723e-05, -5.1756e-02,  5.2859e-02],\n",
            "          [-1.9666e-02, -1.7720e-02,  2.4435e-02]],\n",
            "\n",
            "         [[ 7.2329e-02,  4.2860e-02, -4.4854e-02],\n",
            "          [-3.7911e-02,  4.9807e-03, -2.3330e-02],\n",
            "          [ 6.2506e-02, -8.2072e-02, -7.7328e-02]],\n",
            "\n",
            "         [[-5.1163e-02,  4.5797e-02,  3.3964e-02],\n",
            "          [-3.5975e-02, -7.9299e-02, -8.1962e-02],\n",
            "          [-7.6417e-02,  6.0381e-02,  7.1529e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.0965e-02, -1.4461e-02, -7.7729e-02],\n",
            "          [ 4.9392e-02,  1.7939e-02, -4.9345e-02],\n",
            "          [-6.7323e-02, -2.0458e-03,  2.6508e-02]],\n",
            "\n",
            "         [[-7.7877e-02, -7.1309e-02, -3.6632e-02],\n",
            "          [ 1.2406e-02, -5.1387e-02,  4.1616e-02],\n",
            "          [-7.4030e-02, -2.4033e-02, -2.9774e-02]],\n",
            "\n",
            "         [[-7.1466e-02,  1.2874e-02,  4.2351e-02],\n",
            "          [ 6.5993e-02, -5.5230e-02,  6.6890e-02],\n",
            "          [ 4.8035e-02, -1.0722e-02, -6.3008e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0465e-01,  5.3737e-02,  3.5573e-02],\n",
            "          [ 1.9618e-03,  2.4640e-02, -5.2728e-02],\n",
            "          [ 2.7761e-02,  2.8104e-02,  7.5897e-02]],\n",
            "\n",
            "         [[ 5.7157e-02, -6.2171e-02,  1.0789e-02],\n",
            "          [-2.1555e-02, -7.8780e-02, -7.8639e-02],\n",
            "          [ 4.8880e-02,  7.1540e-02,  1.0834e-02]],\n",
            "\n",
            "         [[ 2.0034e-02,  1.2999e-01,  2.3633e-02],\n",
            "          [ 4.6293e-02,  6.3265e-02, -2.7115e-02],\n",
            "          [ 5.2791e-02,  3.6980e-02, -4.4055e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6817e-02,  1.0919e-01, -4.1701e-02],\n",
            "          [ 8.6614e-02, -3.3371e-02, -3.1012e-02],\n",
            "          [ 1.2059e-03, -7.6649e-02, -6.3505e-02]],\n",
            "\n",
            "         [[-5.3104e-02, -2.0610e-02,  5.2769e-02],\n",
            "          [ 8.5046e-02,  2.5921e-02,  1.0476e-01],\n",
            "          [-3.6069e-03,  3.9456e-02,  5.6042e-02]],\n",
            "\n",
            "         [[ 3.1670e-02,  1.0964e-01,  1.1607e-01],\n",
            "          [-6.3275e-03,  1.3680e-01,  5.1142e-02],\n",
            "          [ 1.4634e-01,  1.5359e-01,  1.1039e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 4.3634e-03, -5.7642e-03,  2.4926e-02],\n",
            "          [ 8.1483e-02,  1.8549e-02, -6.4409e-02],\n",
            "          [ 5.9292e-03,  9.5612e-02, -8.5234e-02]],\n",
            "\n",
            "         [[ 8.9074e-02, -7.1910e-02, -2.4086e-02],\n",
            "          [-1.1457e-02, -2.4191e-02,  1.3768e-02],\n",
            "          [ 1.6569e-04, -3.1512e-02,  3.3423e-02]],\n",
            "\n",
            "         [[ 5.0218e-02,  1.0453e-01,  1.1221e-01],\n",
            "          [ 4.6958e-02,  1.1975e-01, -5.5839e-02],\n",
            "          [ 6.3801e-02, -4.9398e-02,  8.9533e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3894e-02,  6.9275e-02, -5.7682e-02],\n",
            "          [-3.8463e-02,  5.6888e-02, -6.8611e-02],\n",
            "          [-1.0788e-02,  1.5536e-02, -7.2121e-02]],\n",
            "\n",
            "         [[-1.8796e-02,  1.0627e-01, -1.4072e-02],\n",
            "          [ 8.3225e-02,  2.4828e-02,  2.0452e-02],\n",
            "          [ 9.9018e-02,  1.9831e-02, -1.3028e-02]],\n",
            "\n",
            "         [[-8.3875e-03,  4.5869e-02,  1.1413e-01],\n",
            "          [ 5.6041e-02,  2.4721e-02,  5.1714e-02],\n",
            "          [-2.2409e-02,  4.2285e-02, -6.2000e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.7417e-02, -1.6817e-02,  1.1524e-01],\n",
            "          [ 8.8626e-02,  7.7923e-02,  1.6739e-01],\n",
            "          [-1.5965e-02,  6.6070e-02,  1.8409e-01]],\n",
            "\n",
            "         [[ 9.6314e-02,  7.3926e-02,  1.0397e-01],\n",
            "          [ 9.6710e-02,  1.3831e-01,  6.1558e-02],\n",
            "          [-5.4505e-02,  3.6069e-02,  5.0114e-02]],\n",
            "\n",
            "         [[ 1.2115e-01, -3.2534e-03,  2.8468e-02],\n",
            "          [-1.7125e-02,  1.8269e-02,  6.4015e-02],\n",
            "          [-8.9670e-02, -8.6792e-04,  5.3120e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0915e-01,  7.0007e-03,  7.4397e-02],\n",
            "          [-1.1969e-01, -6.5965e-02, -2.1866e-03],\n",
            "          [-1.5821e-01, -1.6181e-01, -5.0571e-02]],\n",
            "\n",
            "         [[ 7.0272e-03,  1.3452e-01,  3.6375e-02],\n",
            "          [ 8.5828e-02, -4.9007e-02,  8.6777e-02],\n",
            "          [ 2.2989e-02, -1.0215e-01, -2.8537e-02]],\n",
            "\n",
            "         [[ 8.1336e-03,  2.1469e-02,  1.3121e-01],\n",
            "          [ 7.5318e-02,  1.0913e-01,  1.2450e-01],\n",
            "          [ 9.4500e-02,  1.0733e-01, -3.2018e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.8465e-03, -7.4338e-02, -2.7802e-02],\n",
            "          [ 2.7106e-02,  1.0313e-01,  9.8583e-02],\n",
            "          [ 9.0787e-02,  1.2888e-01,  6.9701e-02]],\n",
            "\n",
            "         [[ 1.0197e-02,  6.2121e-02, -6.9212e-02],\n",
            "          [ 7.0467e-02,  1.2061e-01,  8.1306e-02],\n",
            "          [-1.4253e-03,  4.0446e-02,  1.2784e-01]],\n",
            "\n",
            "         [[ 7.1633e-02,  9.7789e-02, -4.3715e-02],\n",
            "          [ 1.0765e-01, -2.1096e-02,  7.4788e-02],\n",
            "          [-5.9877e-02, -3.9820e-03, -3.3759e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.1841e-02,  7.7289e-02, -2.1693e-02],\n",
            "          [-2.0918e-02, -6.2087e-02, -6.0833e-02],\n",
            "          [-1.3191e-01, -5.7326e-02,  1.2138e-02]],\n",
            "\n",
            "         [[ 8.3951e-02,  4.0284e-02,  3.4256e-02],\n",
            "          [ 3.0553e-02,  3.5145e-02,  8.5991e-02],\n",
            "          [-5.6503e-02, -1.7151e-02, -7.6543e-03]],\n",
            "\n",
            "         [[ 3.0939e-02,  3.8141e-02, -1.0869e-02],\n",
            "          [ 6.1562e-02,  1.6793e-02,  5.6123e-02],\n",
            "          [ 6.7959e-02,  6.4397e-02,  1.4337e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0158, -0.0544, -0.0302,  0.0293,  0.0987,  0.0162,  0.0577, -0.0511,\n",
            "        -0.0383,  0.0199, -0.0440,  0.1054, -0.0267, -0.0605, -0.0010, -0.0267],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[[[-7.8430e-02, -1.3569e-02,  2.2834e-02],\n",
            "          [-8.1175e-02, -6.6801e-02, -1.9885e-02],\n",
            "          [ 2.6412e-02, -1.9168e-02, -7.9234e-02]],\n",
            "\n",
            "         [[ 4.8847e-02,  3.7706e-02, -5.5216e-02],\n",
            "          [-1.9316e-02, -2.8332e-02, -4.7980e-02],\n",
            "          [-2.4374e-02, -2.0719e-02, -6.1238e-02]],\n",
            "\n",
            "         [[-3.7026e-02, -6.6437e-02, -7.4227e-02],\n",
            "          [-2.7683e-02, -2.2211e-02,  5.9863e-02],\n",
            "          [-6.0338e-02,  9.0929e-02, -1.9159e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8000e-02, -4.9072e-02, -4.1386e-02],\n",
            "          [-4.6839e-02,  2.5878e-02,  3.7259e-02],\n",
            "          [-2.0188e-02,  3.9253e-02,  3.0130e-02]],\n",
            "\n",
            "         [[ 7.9497e-03, -8.8832e-02, -1.2675e-01],\n",
            "          [ 6.9222e-02,  4.3161e-02, -2.9720e-03],\n",
            "          [ 1.3076e-02, -3.4615e-02, -1.5201e-02]],\n",
            "\n",
            "         [[ 2.5416e-02,  5.1954e-02,  6.1906e-02],\n",
            "          [ 7.6804e-02, -5.3204e-03,  9.0222e-03],\n",
            "          [-1.5184e-02,  4.9332e-02, -3.1680e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.2269e-02,  2.7124e-02,  8.4433e-02],\n",
            "          [ 5.0795e-03,  4.1530e-02, -2.0623e-02],\n",
            "          [-2.3315e-02, -7.1500e-02, -9.2301e-02]],\n",
            "\n",
            "         [[ 3.7862e-02,  1.0696e-03, -1.6914e-02],\n",
            "          [-5.8888e-02, -3.4829e-02,  8.2086e-02],\n",
            "          [ 5.7467e-02,  3.5930e-02,  2.9952e-02]],\n",
            "\n",
            "         [[-2.3400e-03, -4.7969e-02, -1.3283e-02],\n",
            "          [ 2.4779e-02,  4.9104e-02,  5.0892e-02],\n",
            "          [ 7.8842e-02, -2.5884e-03,  7.9255e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.7555e-02, -3.2126e-02, -4.8632e-02],\n",
            "          [ 4.9508e-02, -1.0392e-02,  7.6436e-02],\n",
            "          [ 7.7490e-02,  6.5374e-02,  6.1821e-02]],\n",
            "\n",
            "         [[-6.0933e-03, -1.3096e-01, -1.5746e-01],\n",
            "          [-1.8568e-02, -3.4242e-02, -8.8365e-02],\n",
            "          [ 1.0986e-01,  1.5403e-01,  9.1812e-02]],\n",
            "\n",
            "         [[ 4.6110e-02, -8.7465e-02,  6.4513e-02],\n",
            "          [-6.2827e-02,  7.9524e-02,  8.0654e-02],\n",
            "          [-3.6069e-02, -9.7387e-03,  7.8849e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.8927e-02,  6.8056e-02,  5.9456e-02],\n",
            "          [ 2.3470e-02,  6.0844e-02,  6.2459e-02],\n",
            "          [ 4.5926e-02,  4.7180e-02, -1.2734e-02]],\n",
            "\n",
            "         [[-3.2802e-02,  1.0911e-02,  6.3527e-02],\n",
            "          [-3.1667e-02,  5.3861e-02, -2.8885e-02],\n",
            "          [ 7.3318e-03, -1.5119e-02,  7.0020e-02]],\n",
            "\n",
            "         [[-5.9211e-03,  7.0865e-02, -1.5357e-02],\n",
            "          [ 7.3078e-02,  8.9964e-02,  1.5121e-02],\n",
            "          [ 4.0468e-02,  1.1785e-01,  6.2562e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.8177e-02,  3.1005e-02, -2.8970e-02],\n",
            "          [ 7.5034e-02,  4.9659e-02,  1.3888e-02],\n",
            "          [ 9.2734e-02, -1.6627e-02,  5.8639e-02]],\n",
            "\n",
            "         [[ 1.7755e-02, -1.3150e-01, -1.5511e-02],\n",
            "          [ 7.3913e-04, -1.2627e-01, -1.3552e-01],\n",
            "          [ 8.4229e-03,  8.6208e-02, -1.2911e-02]],\n",
            "\n",
            "         [[ 8.4673e-02,  3.5002e-02,  5.0256e-02],\n",
            "          [ 5.8059e-02,  8.8728e-02,  4.7441e-02],\n",
            "          [ 5.0921e-02,  6.0381e-02,  8.7066e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 6.8906e-02,  3.8297e-02,  1.6705e-02],\n",
            "          [-4.8515e-02, -6.7787e-02, -1.1902e-01],\n",
            "          [ 1.8802e-02, -9.6586e-02, -1.5270e-02]],\n",
            "\n",
            "         [[ 4.6010e-02, -3.5331e-02, -1.9662e-03],\n",
            "          [ 5.4358e-02,  5.7844e-02, -6.4695e-03],\n",
            "          [-5.0290e-02, -7.2361e-02,  2.4694e-02]],\n",
            "\n",
            "         [[ 9.5183e-02,  2.0466e-02,  4.7653e-02],\n",
            "          [ 6.9618e-02,  2.4258e-02,  2.6243e-04],\n",
            "          [-1.7968e-02, -7.0110e-02, -1.1560e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.8780e-02,  1.1995e-01, -1.3476e-02],\n",
            "          [ 4.1860e-02,  8.6222e-02, -7.6143e-02],\n",
            "          [ 1.4428e-02, -8.9024e-02, -8.6305e-02]],\n",
            "\n",
            "         [[ 5.4362e-02,  1.9385e-02,  8.8211e-02],\n",
            "          [ 1.0219e-01,  1.7669e-01,  9.2663e-02],\n",
            "          [-5.6358e-02, -8.3383e-02,  5.9461e-02]],\n",
            "\n",
            "         [[ 6.9300e-02,  9.6566e-02, -1.8085e-02],\n",
            "          [ 6.0141e-02, -1.9372e-02,  1.0163e-01],\n",
            "          [-1.0417e-01, -3.2491e-02, -7.9965e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 8.5094e-02,  2.2112e-02, -4.0884e-02],\n",
            "          [-8.3556e-02,  8.4515e-02,  5.7666e-02],\n",
            "          [-1.7764e-02, -9.7103e-02, -7.8444e-02]],\n",
            "\n",
            "         [[-1.3139e-02, -1.7915e-02,  1.8113e-02],\n",
            "          [-7.5397e-02, -4.6448e-02,  1.2203e-03],\n",
            "          [-8.7345e-03, -7.0074e-02,  4.8390e-02]],\n",
            "\n",
            "         [[ 1.3086e-02,  4.7829e-02,  2.7566e-03],\n",
            "          [ 4.1347e-02, -2.7201e-02,  1.0276e-02],\n",
            "          [ 5.6278e-02, -7.1536e-03, -2.2586e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.6622e-02,  7.9345e-02,  5.6783e-02],\n",
            "          [ 4.2907e-02, -2.2685e-02, -1.4352e-04],\n",
            "          [-8.3703e-02, -2.8853e-02, -6.7506e-02]],\n",
            "\n",
            "         [[-5.8223e-04, -9.0837e-02,  1.3288e-02],\n",
            "          [ 1.2537e-01, -1.6081e-02, -4.1066e-02],\n",
            "          [ 6.6518e-02, -1.8491e-02,  4.8171e-02]],\n",
            "\n",
            "         [[ 8.0377e-03, -9.6974e-03, -9.0118e-02],\n",
            "          [ 7.7887e-02,  4.9411e-02,  1.4993e-02],\n",
            "          [ 1.7882e-02,  9.5907e-03,  2.4153e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.1500e-02,  7.5035e-02,  4.4678e-02],\n",
            "          [ 7.7822e-03, -4.2108e-02,  8.8006e-02],\n",
            "          [ 9.3729e-02,  3.7526e-02,  9.0686e-02]],\n",
            "\n",
            "         [[ 7.0842e-02, -8.2821e-03,  1.1510e-02],\n",
            "          [ 2.9586e-02,  6.6829e-02, -8.6819e-03],\n",
            "          [-7.2006e-02,  1.1243e-03, -6.4148e-02]],\n",
            "\n",
            "         [[ 8.2717e-02, -6.2008e-02, -3.0410e-02],\n",
            "          [-7.3000e-02, -9.4134e-02, -5.6998e-02],\n",
            "          [ 2.4939e-02, -1.0407e-01,  3.4140e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.9041e-02,  2.4517e-02,  7.7958e-02],\n",
            "          [-8.7190e-02, -3.3653e-02, -1.4986e-02],\n",
            "          [ 8.0981e-02,  5.7084e-02, -2.5374e-02]],\n",
            "\n",
            "         [[ 7.3036e-02,  5.4267e-02,  1.7845e-02],\n",
            "          [ 5.6365e-02,  5.9080e-02, -2.4615e-02],\n",
            "          [-1.3711e-01, -9.2009e-02, -6.4765e-02]],\n",
            "\n",
            "         [[ 7.0432e-02, -4.3785e-02,  5.8841e-02],\n",
            "          [-7.3467e-02, -8.8335e-02,  7.9189e-02],\n",
            "          [-1.1522e-01, -1.0157e-01,  2.8769e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0352, -0.0441,  0.0147,  0.0531, -0.0388,  0.0556, -0.0529,  0.0741,\n",
            "        -0.0764, -0.0390,  0.0930, -0.0227, -0.0498,  0.0511, -0.0622, -0.0497,\n",
            "        -0.0343, -0.0300,  0.0744,  0.0541,  0.0163,  0.0381,  0.0147,  0.0148,\n",
            "         0.0024, -0.0841,  0.0577,  0.0865, -0.0289,  0.0778, -0.0374,  0.0967],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[[[ 0.0678, -0.0354,  0.0083],\n",
            "          [ 0.0664,  0.0348, -0.0040],\n",
            "          [ 0.0551,  0.0519,  0.0163]],\n",
            "\n",
            "         [[ 0.0330, -0.0495, -0.0253],\n",
            "          [-0.0027, -0.0332,  0.0448],\n",
            "          [-0.0438,  0.0541, -0.0200]],\n",
            "\n",
            "         [[-0.0419,  0.0216,  0.0282],\n",
            "          [-0.0669,  0.0326, -0.0285],\n",
            "          [-0.0135,  0.0349,  0.0576]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0514, -0.0400, -0.0679],\n",
            "          [ 0.0057, -0.0294, -0.0113],\n",
            "          [-0.0575,  0.0203,  0.0034]],\n",
            "\n",
            "         [[ 0.0608,  0.0217,  0.0429],\n",
            "          [ 0.0602,  0.0404,  0.0237],\n",
            "          [ 0.0103,  0.0714,  0.0334]],\n",
            "\n",
            "         [[-0.0875, -0.1230, -0.0554],\n",
            "          [ 0.0377, -0.0895, -0.1047],\n",
            "          [-0.0714, -0.0494, -0.0326]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0447, -0.0132,  0.0259],\n",
            "          [ 0.0374,  0.0719,  0.0091],\n",
            "          [-0.0182, -0.0257,  0.0342]],\n",
            "\n",
            "         [[-0.0215,  0.0714,  0.0618],\n",
            "          [ 0.0322, -0.0192,  0.0414],\n",
            "          [-0.0389, -0.0053, -0.0881]],\n",
            "\n",
            "         [[-0.0311,  0.0354,  0.0717],\n",
            "          [-0.0667,  0.0166,  0.0003],\n",
            "          [-0.0431, -0.0644,  0.0056]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0657, -0.0415, -0.0867],\n",
            "          [ 0.0332,  0.0615,  0.0634],\n",
            "          [ 0.0072,  0.0439,  0.0557]],\n",
            "\n",
            "         [[-0.0102, -0.0297,  0.0487],\n",
            "          [-0.0046,  0.0025,  0.0182],\n",
            "          [-0.0184,  0.0311, -0.0195]],\n",
            "\n",
            "         [[-0.0474, -0.0445, -0.0925],\n",
            "          [-0.0416, -0.0299, -0.0246],\n",
            "          [ 0.0517,  0.0397,  0.0478]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0252, -0.0142,  0.0024],\n",
            "          [-0.0058, -0.0121,  0.0312],\n",
            "          [-0.0197,  0.0284,  0.0401]],\n",
            "\n",
            "         [[-0.0361, -0.0096, -0.0428],\n",
            "          [-0.0086,  0.0746,  0.0255],\n",
            "          [ 0.0174,  0.0754,  0.0444]],\n",
            "\n",
            "         [[-0.0004,  0.0091, -0.0938],\n",
            "          [ 0.0696,  0.0069, -0.0119],\n",
            "          [ 0.0066,  0.0425, -0.0065]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0347,  0.0178,  0.0801],\n",
            "          [-0.0015, -0.0553, -0.0834],\n",
            "          [ 0.0391, -0.0090, -0.0094]],\n",
            "\n",
            "         [[-0.0780, -0.0594,  0.0388],\n",
            "          [ 0.1041,  0.0035, -0.0173],\n",
            "          [ 0.0066,  0.0233,  0.0553]],\n",
            "\n",
            "         [[-0.0156,  0.0514,  0.1192],\n",
            "          [-0.1406,  0.0177,  0.0447],\n",
            "          [ 0.0046, -0.0968, -0.1375]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0194,  0.0021,  0.0038],\n",
            "          [-0.0249, -0.0402,  0.0162],\n",
            "          [-0.0268, -0.0253, -0.0175]],\n",
            "\n",
            "         [[ 0.0617, -0.0375,  0.0370],\n",
            "          [-0.0010, -0.0925,  0.0396],\n",
            "          [-0.0454, -0.0382, -0.0405]],\n",
            "\n",
            "         [[ 0.0299,  0.0440, -0.0439],\n",
            "          [ 0.0283, -0.0402, -0.0570],\n",
            "          [ 0.0635, -0.0478, -0.0467]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0112,  0.0512, -0.0133],\n",
            "          [ 0.0502,  0.0652, -0.0517],\n",
            "          [-0.0252,  0.0404,  0.0013]],\n",
            "\n",
            "         [[ 0.0549,  0.0351,  0.0448],\n",
            "          [-0.0144,  0.0226,  0.0300],\n",
            "          [ 0.0534, -0.0576, -0.0430]],\n",
            "\n",
            "         [[-0.0093, -0.0034,  0.1000],\n",
            "          [ 0.0319,  0.0170,  0.0413],\n",
            "          [ 0.0440, -0.0064,  0.0828]]],\n",
            "\n",
            "\n",
            "        [[[-0.0199, -0.0234,  0.0379],\n",
            "          [-0.0062,  0.0632,  0.0496],\n",
            "          [-0.0048, -0.0282,  0.0896]],\n",
            "\n",
            "         [[-0.0057, -0.0389, -0.0281],\n",
            "          [-0.0193, -0.0526, -0.0086],\n",
            "          [-0.0523, -0.0488,  0.0458]],\n",
            "\n",
            "         [[-0.0024, -0.0108, -0.0024],\n",
            "          [-0.1305, -0.0381, -0.0319],\n",
            "          [-0.0423, -0.1126, -0.0744]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0658,  0.0301,  0.0275],\n",
            "          [ 0.0120,  0.0866,  0.0671],\n",
            "          [-0.0482,  0.0510,  0.0595]],\n",
            "\n",
            "         [[ 0.0654,  0.0524,  0.0007],\n",
            "          [-0.0242,  0.0488,  0.0113],\n",
            "          [-0.0759,  0.0013, -0.0078]],\n",
            "\n",
            "         [[-0.0397, -0.1093, -0.1050],\n",
            "          [ 0.0464,  0.0371,  0.0054],\n",
            "          [ 0.0533,  0.1185,  0.1037]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0644,  0.0697,  0.0012],\n",
            "          [-0.0150,  0.0203, -0.0295],\n",
            "          [ 0.0631, -0.0623, -0.0654]],\n",
            "\n",
            "         [[-0.0265,  0.0689,  0.0291],\n",
            "          [-0.0143,  0.0360,  0.0043],\n",
            "          [ 0.0489, -0.0264, -0.0747]],\n",
            "\n",
            "         [[ 0.0312,  0.0176,  0.0319],\n",
            "          [-0.0006, -0.0404, -0.0486],\n",
            "          [ 0.0526, -0.0386, -0.0161]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0279,  0.0420,  0.0470],\n",
            "          [-0.0654, -0.0050,  0.0676],\n",
            "          [-0.0557,  0.0529,  0.0661]],\n",
            "\n",
            "         [[ 0.0286,  0.0607,  0.0052],\n",
            "          [-0.0068, -0.0356,  0.0579],\n",
            "          [ 0.0255,  0.0304, -0.0057]],\n",
            "\n",
            "         [[ 0.0442, -0.0623, -0.1101],\n",
            "          [-0.0409, -0.0541, -0.0164],\n",
            "          [-0.1321, -0.0301,  0.0182]]]], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0048,  0.0631, -0.0656,  0.0132, -0.0246,  0.0457, -0.0538, -0.0239,\n",
            "        -0.0411,  0.0119, -0.0127,  0.0561,  0.0382, -0.0360, -0.0298,  0.0379,\n",
            "        -0.0237, -0.0618,  0.0015, -0.0420, -0.0240, -0.0201,  0.0806,  0.0585,\n",
            "         0.0262, -0.0501, -0.0454,  0.0296, -0.0314,  0.0450,  0.0550, -0.0676],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0067, -0.0155, -0.0358,  ...,  0.0127, -0.0137,  0.0492],\n",
            "        [ 0.0196,  0.0067, -0.0086,  ...,  0.0077, -0.0139, -0.0004],\n",
            "        [-0.0295, -0.0314,  0.0144,  ...,  0.0150, -0.0312,  0.0005],\n",
            "        ...,\n",
            "        [-0.0124,  0.0161,  0.0066,  ...,  0.0133,  0.0259,  0.0066],\n",
            "        [-0.0100, -0.0117, -0.0123,  ...,  0.0140, -0.0028, -0.0291],\n",
            "        [-0.0001,  0.0209, -0.0086,  ..., -0.0222, -0.0116, -0.0347]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0021, -0.0187, -0.0140,  0.0185, -0.0173, -0.0053,  0.0215,  0.0061,\n",
            "         0.0196, -0.0164,  0.0076, -0.0035, -0.0183,  0.0031, -0.0073,  0.0188,\n",
            "         0.0195,  0.0236,  0.0257, -0.0037,  0.0107,  0.0040, -0.0313, -0.0112,\n",
            "        -0.0055,  0.0106,  0.0320,  0.0066,  0.0319, -0.0208, -0.0230, -0.0189,\n",
            "         0.0092, -0.0144,  0.0074, -0.0052, -0.0096, -0.0205,  0.0082, -0.0030,\n",
            "        -0.0029,  0.0022, -0.0057, -0.0129, -0.0137,  0.0267, -0.0067,  0.0143,\n",
            "        -0.0242,  0.0194,  0.0076,  0.0297,  0.0044,  0.0114, -0.0118,  0.0114,\n",
            "        -0.0210, -0.0237, -0.0246, -0.0086, -0.0193, -0.0298,  0.0114, -0.0225,\n",
            "        -0.0032, -0.0069, -0.0127, -0.0093, -0.0085,  0.0004,  0.0035, -0.0082,\n",
            "         0.0139, -0.0115,  0.0004,  0.0095, -0.0071, -0.0179, -0.0031, -0.0260,\n",
            "        -0.0315, -0.0015,  0.0245, -0.0013,  0.0066, -0.0172,  0.0237,  0.0014,\n",
            "         0.0041,  0.0088, -0.0261,  0.0358, -0.0243, -0.0063,  0.0163, -0.0221,\n",
            "         0.0146,  0.0075, -0.0220,  0.0268,  0.0162,  0.0016,  0.0197, -0.0062,\n",
            "         0.0018, -0.0070, -0.0031, -0.0233,  0.0164,  0.0158,  0.0396, -0.0017,\n",
            "        -0.0077,  0.0053,  0.0010, -0.0048, -0.0032,  0.0049, -0.0116,  0.0307,\n",
            "        -0.0144, -0.0010, -0.0163, -0.0187, -0.0090,  0.0118, -0.0051,  0.0269],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0101, -0.0862,  0.0884,  ...,  0.0684, -0.0011,  0.0134],\n",
            "        [-0.1066, -0.0135, -0.1132,  ..., -0.0315, -0.0153, -0.0987],\n",
            "        [-0.0126, -0.0569,  0.1049,  ..., -0.0585,  0.0914,  0.0004],\n",
            "        ...,\n",
            "        [ 0.0533, -0.0257, -0.0420,  ..., -0.0416, -0.0813,  0.0784],\n",
            "        [ 0.0157,  0.0105, -0.0227,  ...,  0.0859,  0.0519,  0.0019],\n",
            "        [ 0.0900,  0.0397,  0.0311,  ...,  0.0674, -0.0585, -0.1561]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0444,  0.0353, -0.0037,  0.0557,  0.0475, -0.0323, -0.0064,  0.0064,\n",
            "        -0.0487,  0.0607], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[p.numel() for p in cnn.parameters() if p.requires_grad]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcpdksRkLfTq",
        "outputId": "0ed02f38-8aa7-41db-cf52-798c5e7e3b19"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[144, 16, 2304, 16, 4608, 32, 9216, 32, 200704, 128, 1280, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I3pjI6hBL9yN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}